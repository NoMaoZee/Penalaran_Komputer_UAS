{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TAHAP 4\n",
        "## Penalaran Komputer UAS\n",
        "## **Anggota:**\n",
        "## Haidar Dimas Heryanto - 202210370311088\n",
        "## Zeedan Mustami Argani - 202210370311104"
      ],
      "metadata": {
        "id": "aPVfWcY-TWZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oecPRZoppsga"
      },
      "outputs": [],
      "source": [
        "# 04_Solution_Reuse.ipynb\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import Counter # For majority vote\n",
        "import nltk\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas requests beautifulsoup4 pdfminer.six lxml > /dev/null 2>&1\n",
        "\n",
        "import argparse\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import urllib\n",
        "from concurrent.futures import ThreadPoolExecutor, wait\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pdfminer import high_level # For PDF text extraction\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- NLTK Setup (for word counting) ---\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    # Add this line to also check and download 'punkt_tab'\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    print(\"NLTK 'punkt' or 'punkt_tab' not found. Downloading...\")\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('punkt_tab') # Download the missing resource\n",
        "    print(\"NLTK 'punkt' and 'punkt_tab' downloaded.\")\n",
        "except Exception as e:\n",
        "     print(f\"An unexpected error occurred during NLTK setup: {e}\")"
      ],
      "metadata": {
        "id": "oMDqQ10s0X3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For BERT (if chosen for retrieval)\n",
        "# !pip install transformers sentence-transformers > /dev/null 2>&1 # Already installed in N3 if used\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# --- Configuration Section ---\n",
        "# !!! IMPORTANT: Ensure these paths match your Google Drive structure\n",
        "# and the outputs from previous notebooks !!!\n",
        "BASE_DRIVE_PATH = \"/content/drive/MyDrive/Penalaran Komputer UAS/\" # Change to your project folder\n",
        "\n",
        "# Paths for input data\n",
        "PATH_PROCESSED_INPUT = os.path.join(BASE_DRIVE_PATH, \"data/processed\")\n",
        "PROCESSED_CSV_FILENAME = \"cases_processed.csv\"\n",
        "PATH_EVAL_INPUT = os.path.join(BASE_DRIVE_PATH, \"data/eval\")\n",
        "QUERIES_JSON_FILENAME = \"queries.json\"\n",
        "\n",
        "# Path for output results\n",
        "PATH_RESULTS_OUTPUT = os.path.join(BASE_DRIVE_PATH, \"data/results\")\n",
        "os.makedirs(PATH_RESULTS_OUTPUT, exist_ok=True)\n",
        "PREDICTIONS_CSV_FILENAME = \"predictions.csv\"\n",
        "\n",
        "# BERT Model (must be same as in Notebook 3 if using BERT)\n",
        "BERT_MODEL_NAME = 'indobenchmark/indobert-base-p1'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Field in processed_cases_df to be used as \"solution\"\n",
        "SOLUTION_FIELD = 'amar_kategori' # As per PDF, can be 'amar putusan' or 'ringkasan dakwaan'\n",
        "\n",
        "# --- NLTK Setup (for preprocessing if needed for TF-IDF) ---\n",
        "# Corrected exception handling to catch LookupError\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError: # Catch the actual LookupError raised by nltk.data.find\n",
        "    print(\"NLTK 'punkt' or 'stopwords' not found. Downloading...\")\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    print(\"NLTK resources downloaded.\")\n",
        "except Exception as e:\n",
        "     print(f\"An unexpected error occurred during NLTK setup: {e}\")\n",
        "\n",
        "\n",
        "# Check if stopwords were downloaded successfully\n",
        "try:\n",
        "    indonesian_stopwords = nltk.corpus.stopwords.words('indonesian')\n",
        "except LookupError:\n",
        "    print(\"Could not load Indonesian stopwords. Please check NLTK download.\")\n",
        "    indonesian_stopwords = []"
      ],
      "metadata": {
        "id": "mvy4ZsTlWpm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions (Reused/Adapted from Notebook 3) ---\n",
        "def preprocess_text_for_tfidf(text):\n",
        "    if pd.isna(text) or not text: return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [word for word in words if word not in indonesian_stopwords and word.isalpha()]\n",
        "    return \" \".join(words)\n",
        "\n",
        "def load_data_and_models():\n",
        "    \"\"\"Loads processed cases, TF-IDF vectorizer, case vectors, BERT components, etc.\"\"\"\n",
        "    global df_cases, fitted_tfidf_vectorizer, case_vectors_tfidf, case_ids_global_tfidf\n",
        "    global bert_tokenizer, bert_model, case_embeddings_bert, case_ids_global_bert\n",
        "    global RETRIEVAL_TEXT_SOURCE_COLUMN\n",
        "\n",
        "    # Load processed cases\n",
        "    processed_data_filepath = os.path.join(PATH_PROCESSED_INPUT, PROCESSED_CSV_FILENAME)\n",
        "    try:\n",
        "        df_cases = pd.read_csv(processed_data_filepath)\n",
        "        print(f\"Successfully loaded processed data from: {processed_data_filepath} with shape {df_cases.shape}\")\n",
        "\n",
        "        # Determine retrieval text source (consistent with N3)\n",
        "        if 'ringkasan_fakta' in df_cases.columns and not df_cases['ringkasan_fakta'].isna().all():\n",
        "            RETRIEVAL_TEXT_SOURCE_COLUMN = 'ringkasan_fakta'\n",
        "        else:\n",
        "            RETRIEVAL_TEXT_SOURCE_COLUMN = 'text_full'\n",
        "        df_cases[RETRIEVAL_TEXT_SOURCE_COLUMN] = df_cases[RETRIEVAL_TEXT_SOURCE_COLUMN].fillna('')\n",
        "        print(f\"Using '{RETRIEVAL_TEXT_SOURCE_COLUMN}' for retrieval text source.\")\n",
        "\n",
        "        if SOLUTION_FIELD not in df_cases.columns:\n",
        "            print(f\"Error: Solution field '{SOLUTION_FIELD}' not found in df_cases. Prediction will fail.\")\n",
        "            # Fallback or handle error\n",
        "            df_cases[SOLUTION_FIELD] = \"SOLUTION_NOT_AVAILABLE\"\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Processed data file not found at {processed_data_filepath}.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading processed data: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Initialize TF-IDF components (re-fit based on loaded data)\n",
        "    print(\"\\n[Initializing and Fitting TF-IDF Components...]\")\n",
        "    tfidf_vectorizer_local = TfidfVectorizer(preprocessor=preprocess_text_for_tfidf, max_df=0.95, min_df=2, ngram_range=(1,2))\n",
        "    texts_for_tfidf = df_cases[RETRIEVAL_TEXT_SOURCE_COLUMN].tolist()\n",
        "    try:\n",
        "        case_vectors_tfidf = tfidf_vectorizer_local.fit_transform(texts_for_tfidf)\n",
        "        fitted_tfidf_vectorizer = tfidf_vectorizer_local # Assign to global\n",
        "        case_ids_global_tfidf = df_cases['case_id'].tolist()\n",
        "        print(f\"TF-IDF fitting complete. Shape: {case_vectors_tfidf.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fitting TF-IDF: {e}\")\n",
        "        fitted_tfidf_vectorizer = None # Ensure it's None if failed\n",
        "\n",
        "    # Initialize BERT components (re-generate embeddings or load if saved - for simplicity, re-generate)\n",
        "    print(\"\\n[Initializing BERT Components and Generating Embeddings...]\")\n",
        "    try:\n",
        "        bert_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "        bert_model = AutoModel.from_pretrained(BERT_MODEL_NAME).to(DEVICE)\n",
        "        bert_model.eval()\n",
        "        print(f\"BERT model '{BERT_MODEL_NAME}' loaded successfully.\")\n",
        "\n",
        "        texts_for_bert = df_cases[RETRIEVAL_TEXT_SOURCE_COLUMN].tolist()\n",
        "        embeddings_list = []\n",
        "        BERT_EMBEDDING_DIM = bert_model.config.hidden_size # Get dim from model\n",
        "        for i, text in enumerate(texts_for_bert):\n",
        "            if (i + 1) % 20 == 0 or i == len(texts_for_bert) - 1 : print(f\"  BERT embedding for doc {i+1}/{len(texts_for_bert)}\")\n",
        "            inputs = bert_tokenizer(str(text).strip() if pd.notna(text) else \"\", return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "            with torch.no_grad(): outputs = bert_model(**inputs)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy().squeeze()\n",
        "            embeddings_list.append(cls_embedding if cls_embedding.size > 0 else np.zeros(BERT_EMBEDDING_DIM))\n",
        "\n",
        "        if embeddings_list:\n",
        "            case_embeddings_bert = np.array(embeddings_list)\n",
        "            case_ids_global_bert = df_cases['case_id'].tolist()\n",
        "            print(f\"BERT embeddings generation complete. Shape: {case_embeddings_bert.shape}\")\n",
        "        else: case_embeddings_bert = None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load/run BERT model '{BERT_MODEL_NAME}': {e}. BERT retrieval will not be available.\")\n",
        "        bert_tokenizer, bert_model, case_embeddings_bert = None, None, None\n",
        "    return True\n",
        "\n",
        "\n",
        "# --- Retrieval Function (Adapted from N3 to return scores) ---\n",
        "def retrieve_cases_with_scores(query_text, retrieval_method=\"tfidf\", k=5):\n",
        "    \"\"\"Retrieves top-k similar case IDs and their similarity scores.\"\"\"\n",
        "    results = [] # List of (case_id, score)\n",
        "    if retrieval_method == \"tfidf\":\n",
        "        if fitted_tfidf_vectorizer is None or case_vectors_tfidf is None: return []\n",
        "        processed_query = preprocess_text_for_tfidf(query_text)\n",
        "        query_vector = fitted_tfidf_vectorizer.transform([processed_query])\n",
        "        similarities = cosine_similarity(query_vector, case_vectors_tfidf).flatten()\n",
        "        top_k_indices = similarities.argsort()[-k:][::-1]\n",
        "        results = [(case_ids_global_tfidf[i], similarities[i]) for i in top_k_indices]\n",
        "\n",
        "    elif retrieval_method == \"bert\":\n",
        "        if case_embeddings_bert is None or not bert_model: return []\n",
        "        BERT_EMBEDDING_DIM = bert_model.config.hidden_size\n",
        "        query_input_text = str(query_text).strip()\n",
        "        if not query_input_text: query_embedding = np.zeros(BERT_EMBEDDING_DIM)\n",
        "        else:\n",
        "            inputs = bert_tokenizer(query_input_text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "            inputs = {k_in: v_in.to(DEVICE) for k_in, v_in in inputs.items()}\n",
        "            with torch.no_grad(): outputs = bert_model(**inputs)\n",
        "            query_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy().squeeze()\n",
        "\n",
        "        query_embedding = query_embedding.reshape(1, -1)\n",
        "        similarities = cosine_similarity(query_embedding, case_embeddings_bert).flatten()\n",
        "        top_k_indices = similarities.argsort()[-k:][::-1]\n",
        "        results = [(case_ids_global_bert[i], similarities[i]) for i in top_k_indices]\n",
        "    return results\n",
        "\n",
        "# --- Tahap 4.a: Ekstrak Solusi ---\n",
        "def get_solution_for_case(case_id, df_cases_local, solution_field_local=SOLUTION_FIELD):\n",
        "    \"\"\"Extracts the solution text for a given case_id.\"\"\"\n",
        "    solution_series = df_cases_local.loc[df_cases_local['case_id'] == case_id, solution_field_local]\n",
        "    return solution_series.iloc[0] if not solution_series.empty else \"SOLUTION_NOT_FOUND\"\n",
        "\n",
        "# --- Tahap 4.b: Algoritma Prediksi ---\n",
        "def majority_vote_solution(retrieved_solutions_texts):\n",
        "    \"\"\"Determines the most common solution text by majority vote.\"\"\"\n",
        "    if not retrieved_solutions_texts: return \"NO_SOLUTION_RETRIEVED\"\n",
        "    vote_counts = Counter(retrieved_solutions_texts)\n",
        "    most_common = vote_counts.most_common(1)\n",
        "    return most_common[0][0] if most_common else \"TIE_OR_EMPTY_VOTE\"\n",
        "\n",
        "def weighted_similarity_solution(retrieved_cases_with_scores_list, df_cases_local, solution_field_local=SOLUTION_FIELD):\n",
        "    \"\"\"Determines solution based on weighted similarity scores.\"\"\"\n",
        "    if not retrieved_cases_with_scores_list: return \"NO_SOLUTION_RETRIEVED_FOR_WEIGHTED\"\n",
        "\n",
        "    solution_scores = {} # {'solution_text_A': total_score, 'solution_text_B': total_score}\n",
        "    for case_id, score in retrieved_cases_with_scores_list:\n",
        "        solution_text = get_solution_for_case(case_id, df_cases_local, solution_field_local)\n",
        "        if solution_text == \"SOLUTION_NOT_FOUND\" or solution_text == \"SOLUTION_NOT_AVAILABLE\": continue # Skip if no valid solution\n",
        "        solution_scores[solution_text] = solution_scores.get(solution_text, 0) + score\n",
        "\n",
        "    if not solution_scores: return \"NO_VALID_SOLUTIONS_FOR_WEIGHTING\"\n",
        "    # Return the solution text with the highest aggregated score\n",
        "    return max(solution_scores, key=solution_scores.get)\n",
        "\n",
        "\n",
        "# --- Tahap 4.c: Implementasi Fungsi predict_outcome ---\n",
        "def predict_outcome(query_text, df_cases_local, retrieval_method=\"tfidf\", k_retrieve=5,\n",
        "                    prediction_algorithm=\"majority_vote\", solution_field_param=SOLUTION_FIELD):\n",
        "    \"\"\"\n",
        "    Predicts an outcome for a query based on retrieved similar cases.\n",
        "    Returns predicted_solution_text and list of top_k_case_ids.\n",
        "    \"\"\"\n",
        "    top_k_cases_with_scores = retrieve_cases_with_scores(query_text, retrieval_method=retrieval_method, k=k_retrieve) #\n",
        "\n",
        "    if not top_k_cases_with_scores:\n",
        "        return \"NO_SIMILAR_CASES_FOUND\", []\n",
        "\n",
        "    top_k_case_ids_only = [case_id for case_id, score in top_k_cases_with_scores]\n",
        "    retrieved_solutions_texts = [get_solution_for_case(cid, df_cases_local, solution_field_param) for cid in top_k_case_ids_only] #\n",
        "    # Filter out cases where solution might not be found (though get_solution_for_case handles this)\n",
        "    valid_solutions = [s for s in retrieved_solutions_texts if s not in [\"SOLUTION_NOT_FOUND\", \"SOLUTION_NOT_AVAILABLE\"]]\n",
        "\n",
        "\n",
        "    predicted_solution = \"PREDICTION_FAILED\"\n",
        "    if not valid_solutions:\n",
        "         predicted_solution = \"NO_VALID_SOLUTIONS_IN_TOP_K\"\n",
        "    elif prediction_algorithm == \"majority_vote\": #\n",
        "        predicted_solution = majority_vote_solution(valid_solutions)\n",
        "    elif prediction_algorithm == \"weighted_similarity\": #\n",
        "        # We need to pass the original scores along with case_ids to the weighting function\n",
        "        valid_cases_for_weighting = []\n",
        "        for case_id, score in top_k_cases_with_scores:\n",
        "            solution_text_temp = get_solution_for_case(case_id, df_cases_local, solution_field_param)\n",
        "            if solution_text_temp not in [\"SOLUTION_NOT_FOUND\", \"SOLUTION_NOT_AVAILABLE\"]:\n",
        "                valid_cases_for_weighting.append((case_id, score)) # Use only cases with valid solutions\n",
        "\n",
        "        if valid_cases_for_weighting:\n",
        "            predicted_solution = weighted_similarity_solution(valid_cases_for_weighting, df_cases_local, solution_field_param)\n",
        "        else:\n",
        "            predicted_solution = \"NO_VALID_SOLUTIONS_FOR_WEIGHTING_IN_TOP_K\"\n",
        "    else:\n",
        "        predicted_solution = \"UNKNOWN_PREDICTION_ALGORITHM\"\n",
        "\n",
        "    return predicted_solution, top_k_case_ids_only\n",
        "\n",
        "\n",
        "# --- Tahap 4.d: Demo Manual & Output ---\n",
        "def run_prediction_demo_and_save():\n",
        "    global df_cases # Ensure df_cases is accessible\n",
        "    queries_json_filepath = os.path.join(PATH_EVAL_INPUT, QUERIES_JSON_FILENAME)\n",
        "    try:\n",
        "        with open(queries_json_filepath, 'r', encoding='utf-8') as f:\n",
        "            queries_for_demo = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Queries file not found at {queries_json_filepath}. Cannot run demo.\")\n",
        "        # Create some dummy queries if file not found for demo purposes\n",
        "        queries_for_demo = [{\"query_id\": \"DemoQ1\", \"query_text\": \"Contoh query pidana militer tentang desersi\"}]\n",
        "        if df_cases is not None and not df_cases.empty: # try to get a real query text from df_cases\n",
        "            queries_for_demo[0][\"query_text\"] = df_cases[RETRIEVAL_TEXT_SOURCE_COLUMN].iloc[0][:100] # use first case's text\n",
        "        print(\"Using dummy queries for demo as queries.json was not found.\")\n",
        "\n",
        "\n",
        "    predictions_log = []\n",
        "    retrieval_choice = \"tfidf\" # Choose 'tfidf' or 'bert'\n",
        "    # Check if BERT is usable\n",
        "    if bert_model is None or case_embeddings_bert is None:\n",
        "        print(\"BERT model/embeddings not available, defaulting retrieval to TF-IDF for predictions.\")\n",
        "        retrieval_choice = \"tfidf\"\n",
        "    if fitted_tfidf_vectorizer is None:\n",
        "        print(\"TF-IDF model not available. Predictions might fail.\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Running Prediction Demo (using {retrieval_choice} for retrieval and {SOLUTION_FIELD} as solution) ---\")\n",
        "\n",
        "    # As per PDF: \"Siapkan 5 contoh kasus baru\"  - we'll use queries from queries.json\n",
        "    for query_data in queries_for_demo[:5]: # Demo with up to 5 queries\n",
        "        query_id = query_data['query_id']\n",
        "        query_text = query_data['query_text']\n",
        "        print(f\"\\nProcessing Query ID: {query_id} - Query: \\\"{query_text[:100]}...\\\"\")\n",
        "\n",
        "        # Predict using majority vote\n",
        "        predicted_sol_majority, top_k_ids_majority = predict_outcome(\n",
        "            query_text, df_cases, retrieval_method=retrieval_choice, k_retrieve=5,\n",
        "            prediction_algorithm=\"majority_vote\"\n",
        "        )\n",
        "        print(f\"  Predicted Solution (Majority Vote): {predicted_sol_majority[:200]}...\") # Print preview\n",
        "        predictions_log.append({\n",
        "            \"query_id\": query_id,\n",
        "            \"query_text_preview\": query_text[:100]+\"...\",\n",
        "            \"retrieval_method\": retrieval_choice,\n",
        "            \"prediction_algorithm\": \"majority_vote\",\n",
        "            \"predicted_solution\": predicted_sol_majority,\n",
        "            \"top_5_case_ids\": \", \".join(top_k_ids_majority)\n",
        "        })\n",
        "\n",
        "        # Predict using weighted similarity\n",
        "        predicted_sol_weighted, top_k_ids_weighted = predict_outcome(\n",
        "            query_text, df_cases, retrieval_method=retrieval_choice, k_retrieve=5,\n",
        "            prediction_algorithm=\"weighted_similarity\"\n",
        "        )\n",
        "        print(f\"  Predicted Solution (Weighted Similarity): {predicted_sol_weighted[:200]}...\") # Print preview\n",
        "        predictions_log.append({\n",
        "            \"query_id\": query_id,\n",
        "            \"query_text_preview\": query_text[:100]+\"...\",\n",
        "            \"retrieval_method\": retrieval_choice,\n",
        "            \"prediction_algorithm\": \"weighted_similarity\",\n",
        "            \"predicted_solution\": predicted_sol_weighted,\n",
        "            \"top_5_case_ids\": \", \".join(top_k_ids_weighted) # Assuming same top-k for both algos here for simplicity\n",
        "        })\n",
        "\n",
        "    # Save predictions to CSV\n",
        "    if predictions_log:\n",
        "        df_predictions = pd.DataFrame(predictions_log)\n",
        "        predictions_csv_filepath = os.path.join(PATH_RESULTS_OUTPUT, PREDICTIONS_CSV_FILENAME)\n",
        "        df_predictions.to_csv(predictions_csv_filepath, index=False, encoding='utf-8')\n",
        "        print(f\"\\nPredictions saved to: {predictions_csv_filepath}\")\n",
        "        display(df_predictions)\n",
        "    else:\n",
        "        print(\"No predictions were logged.\")"
      ],
      "metadata": {
        "id": "YAg-LOqCWrbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Tahap 4: Solution Reuse\")\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    # Load data and initialize/fit models\n",
        "    # This is crucial as Notebook 4 reuses retrieval components.\n",
        "    # These components need the case base data.\n",
        "    if load_data_and_models():\n",
        "        run_prediction_demo_and_save()\n",
        "    else:\n",
        "        print(\"Failed to load data or initialize models. Cannot run prediction demo.\")\n",
        "\n",
        "    print(\"\\nTahap 4: Solution Reuse - Complete.\")"
      ],
      "metadata": {
        "id": "X-atvsRJWtAS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}