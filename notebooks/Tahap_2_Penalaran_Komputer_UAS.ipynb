{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TAHAP 2\n",
        "## Penalaran Komputer UAS\n",
        "## **Anggota:**\n",
        "## Haidar Dimas Heryanto - 202210370311088\n",
        "## Zeedan Mustami Argani - 202210370311104"
      ],
      "metadata": {
        "id": "_Q70cWDiTmrE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1IfE7az3p4aq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import drive\n",
        "import nltk # Using NLTK for tokenization to count words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas requests beautifulsoup4 pdfminer.six lxml > /dev/null 2>&1\n",
        "\n",
        "import argparse\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import urllib\n",
        "from concurrent.futures import ThreadPoolExecutor, wait\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pdfminer import high_level # For PDF text extraction\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Am2H8rQzEWv",
        "outputId": "a02214db-926e-4f46-9e1f-53f84c6939d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration Section ---\n",
        "BASE_DRIVE_PATH = \"/content/drive/MyDrive/Penalaran Komputer UAS/\" # Change to your project folder\n",
        "\n",
        "# Paths for input data from Notebook 1\n",
        "PATH_RAW_TEXT_INPUT = os.path.join(BASE_DRIVE_PATH, \"data/raw\")\n",
        "PATH_INITIAL_SCRAPER_CSV_INPUT = os.path.join(BASE_DRIVE_PATH, \"Scraper_CSVs\")\n",
        "\n",
        "# Path for output processed data\n",
        "PATH_PROCESSED_OUTPUT = os.path.join(BASE_DRIVE_PATH, \"data/processed\")\n",
        "os.makedirs(PATH_PROCESSED_OUTPUT, exist_ok=True)\n",
        "\n",
        "# --- NLTK Setup (for word counting) ---\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    # Add this line to also check and download 'punkt_tab'\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    print(\"NLTK 'punkt' or 'punkt_tab' not found. Downloading...\")\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('punkt_tab') # Download the missing resource\n",
        "    print(\"NLTK 'punkt' and 'punkt_tab' downloaded.\")\n",
        "except Exception as e:\n",
        "     print(f\"An unexpected error occurred during NLTK setup: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5ewscU2UaTk",
        "outputId": "363fc52a-9b73-4fac-dc51-dc315edd8a53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK 'punkt' or 'punkt_tab' not found. Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK 'punkt' and 'punkt_tab' downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions ---\n",
        "\n",
        "def load_latest_scraper_csv(csv_folder_path):\n",
        "    \"\"\"Loads the most recently created CSV file from the specified folder.\"\"\"\n",
        "    try:\n",
        "        csv_files = [f for f in os.listdir(csv_folder_path) if f.endswith('.csv')]\n",
        "        if not csv_files:\n",
        "            print(f\"No CSV files found in {csv_folder_path}\")\n",
        "            return None\n",
        "        # Find the latest file based on filename pattern (if includes date) or modification time\n",
        "        # Assuming filenames might include dates like 'putusan_ma_KEYWORD_YYYY-MM-DD.csv'\n",
        "        csv_files.sort(key=lambda name: os.path.getmtime(os.path.join(csv_folder_path, name)), reverse=True)\n",
        "        latest_csv_filename = csv_files[0]\n",
        "        print(f\"Loading latest scraper CSV: {latest_csv_filename}\")\n",
        "        return pd.read_csv(os.path.join(csv_folder_path, latest_csv_filename))\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading latest CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_raw_text_file(filename, raw_text_folder):\n",
        "    \"\"\"Reads the content of a raw text file.\"\"\"\n",
        "    if not filename or filename.strip().upper() == \"A\":\n",
        "        print(f\"Skipping invalid filename: '{filename}'\")\n",
        "        return \"\"\n",
        "\n",
        "    filepath = os.path.join(raw_text_folder, filename)\n",
        "\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Warning: Raw text file does not exist: {filepath}\")\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading raw text file {filepath}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def count_words(text):\n",
        "    \"\"\"Counts words in a text using NLTK tokenization.\"\"\"\n",
        "    if pd.isna(text) or not text:\n",
        "        return 0\n",
        "    tokens = nltk.word_tokenize(str(text))\n",
        "    return len(tokens)\n",
        "\n",
        "def extract_section_heuristic(text, keywords_start, keywords_end=None, limit_chars=5000, verbose=False):\n",
        "    \"\"\"\n",
        "    Extracts a section of text based on start and optional end keywords using heuristics.\n",
        "    - If start keyword found but end keyword not found: extract until limit_chars or end of text.\n",
        "    - If both found: extract between them.\n",
        "    - If none found: return \"\".\n",
        "\n",
        "    Parameters:\n",
        "        text (str): Full document text.\n",
        "        keywords_start (list): List of regex patterns (strings) for start.\n",
        "        keywords_end (list): List of regex patterns (strings) for end (optional).\n",
        "        limit_chars (int): Max character length of extracted segment.\n",
        "        verbose (bool): If True, print debug information.\n",
        "\n",
        "    Returns:\n",
        "        str: Extracted text section.\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or not text:\n",
        "        return \"\"\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    start_index = -1\n",
        "    matched_start_keyword = None\n",
        "\n",
        "    # 1. Cari start keyword\n",
        "    for kw_pattern in keywords_start:\n",
        "        match = re.search(kw_pattern, text_lower)\n",
        "        if match:\n",
        "            start_index = match.end()\n",
        "            matched_start_keyword = kw_pattern\n",
        "            break\n",
        "\n",
        "    if start_index == -1:\n",
        "        if verbose:\n",
        "            print(\"[extract_section_heuristic] Start keyword not found.\")\n",
        "        return \"\"\n",
        "\n",
        "    # 2. Cari end keyword (opsional)\n",
        "    end_index = len(text)\n",
        "    matched_end_keyword = None\n",
        "\n",
        "    if keywords_end:\n",
        "        found_end = False\n",
        "        for kw_pattern in keywords_end:\n",
        "            match = re.search(kw_pattern, text_lower[start_index:])\n",
        "            if match:\n",
        "                temp_end_index = start_index + match.start()\n",
        "                if temp_end_index < end_index:\n",
        "                    end_index = temp_end_index\n",
        "                    matched_end_keyword = kw_pattern\n",
        "                    found_end = True\n",
        "\n",
        "        if not found_end and verbose:\n",
        "            print(f\"[extract_section_heuristic] End keyword not found. Extracting until limit ({limit_chars}).\")\n",
        "\n",
        "    extracted = text[start_index:end_index].strip()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[extract_section_heuristic] Start match: {matched_start_keyword}\")\n",
        "        print(f\"[extract_section_heuristic] End match: {matched_end_keyword}\")\n",
        "        print(f\"[extract_section_heuristic] Extracted length: {len(extracted)} chars\")\n",
        "\n",
        "    return extracted[:limit_chars]"
      ],
      "metadata": {
        "id": "juwD7Ua8Ud37"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Processing Logic ---\n",
        "print(\"Starting Tahap 2: Case Representation\")\n",
        "\n",
        "# 1. Load initial data (CSV from scraper and raw text files)\n",
        "print(f\"\\n[1. Loading Data]\")\n",
        "df_initial = load_latest_scraper_csv(PATH_INITIAL_SCRAPER_CSV_INPUT)\n",
        "\n",
        "# --- Filter rows: Remove rows with 'A' or NaN in 'nama_file_raw_text' ---\n",
        "if 'nama_file_raw_text' in df_initial.columns:\n",
        "    df_initial = df_initial[\n",
        "        df_initial['nama_file_raw_text'].notna() &  # Bukan NaN\n",
        "        ~df_initial['nama_file_raw_text'].str.contains(r'\\bA\\b', na=False)  # Tidak mengandung huruf A tunggal\n",
        "    ]\n",
        "    print(f\"Filtered data, remaining rows after removing invalid 'nama_file_raw_text': {len(df_initial)}\")\n",
        "\n",
        "if df_initial is None or df_initial.empty:\n",
        "    print(\"Could not load initial scraper CSV. Please ensure Notebook 1 ran successfully and the CSV exists.\")\n",
        "    # Exit or handle error appropriately\n",
        "else:\n",
        "    print(f\"Loaded initial data with {len(df_initial)} records.\")\n",
        "    # Ensure 'nama_file_raw_text' column exists\n",
        "    if 'nama_file_raw_text' not in df_initial.columns:\n",
        "        print(\"ERROR: 'nama_file_raw_text' column not found in the CSV. This column is needed to load full text.\")\n",
        "        # Exit or handle\n",
        "    else:\n",
        "        # Load full text for each case\n",
        "        df_initial['full_text_putusan'] = df_initial['nama_file_raw_text'].apply(\n",
        "            lambda x: read_raw_text_file(x, PATH_RAW_TEXT_INPUT) if pd.notna(x) else \"\"\n",
        "        )\n",
        "        print(\"Full text loaded into DataFrame.\")\n",
        "\n",
        "        # Initialize new columns for extracted features\n",
        "        df_initial['ringkasan_fakta'] = \"\"\n",
        "        df_initial['argumen_hukum_utama'] = \"\"\n",
        "        df_initial['pasal_digunakan_extracted'] = \"\" # For refined pasal extraction\n",
        "        df_initial['pihak_terlibat_extracted'] = \"\"   # For refined pihak extraction\n",
        "\n",
        "        # 2. Metadata Extraction & Refinement\n",
        "        # Most metadata (nomor perkara, tanggal, jenis perkara) is already in df_initial from the scraper.\n",
        "        # We might want to refine 'pasal_digunakan' and 'nama_pihak' if the initial scrape was basic.\n",
        "        print(f\"\\n[2. Extracting/Refining Metadata & Text Features]\")\n",
        "\n",
        "        # Keywords for extracting \"Ringkasan Fakta\"\n",
        "        # These are examples and might need adjustment based on actual document structures\n",
        "        fakta_keywords_start = [\n",
        "            r\"tentang pokok sengketa pengajuan peninjauan kembali\",\n",
        "            r\"alasan dan penjelasan permohonan banding\",\n",
        "            r\"alasan permohonan banding\",\n",
        "            r\"pokok sengketa;\",\n",
        "            r\"kronologis sengketa pajak\",\n",
        "            r\"menimbang,\\s*bahwa\\s*terdakwa\\s*diajukan\\s*ke\\s*persidangan\",\n",
        "            r\"menimbang,\\s*bahwa\\s*penggugat\\s*dalam\\s*surat\\s*gugatannya\",\n",
        "            r\"duduk\\s*perkara:\",\n",
        "            r\"fakta-fakta\\s*hukum\\s*yang\\s*terungkap\",\n",
        "            r\"menimbang,\\s*bahwa\\s*untuk\\s*membuktikan\\s*dalil-dalilnya\",\n",
        "            r\"uraian\\s*singkat\\s*mengenai\\s*kejadian\",\n",
        "            r\"tentang\\s*duduk\\s*perkara\"\n",
        "        ]\n",
        "        fakta_keywords_end = [ # Stop before legal considerations or verdict\n",
        "            r\"pertimbangan hukum\",\n",
        "            r\"tentang pertimbangan hukum\",\n",
        "            r\"menimbang, bahwa terhadap alasan-alasan peninjauan kembali\",\n",
        "            r\"menimbang,\\s*bahwa\\s*selanjutnya\\s*majelis\\s*hakim\\s*akan\\s*mempertimbangkan\",\n",
        "            r\"pertimbangan\\s*hukum\",\n",
        "            r\"tentang\\s*pertimbangan\\s*hukum\",\n",
        "            r\"amar\\s*putusan\",\n",
        "            r\"mengadili\",\n",
        "            r\"permohonan kasasi\", r\"duduk\\s*sengketa\", r\"pertimbangan\\s*permohonan\",\n",
        "            r\"permohonan pemohon\", r\"kejadian perkara\", r\"uraian kejadian\"\n",
        "        ]\n",
        "\n",
        "        # Keywords for \"Argumen Hukum Utama\" (Pertimbangan Hukum)\n",
        "        argumen_keywords_start = [\n",
        "            r\"pertimbangan hukum\", # Header utama\n",
        "            r\"menimbang, bahwa terhadap alasan-alasan peninjauan kembali tersebut, mahkamah agung berpendapat\",\n",
        "            r\"menimbang, bahwa alasan-alasan permohonan pemohon peninjauan kembali tidak dapat dibenarkan\",\n",
        "            r\"menimbang, bahwa alasan-alasan permohonan pemohon peninjauan kembali dapat dibenarkan\",\n",
        "            r\"pertimbangan\\s*hukum\",\n",
        "            r\"tentang\\s*pertimbangan\\s*hukum\",\n",
        "            r\"menimbang,\\s*bahwa\\s*terhadap\\s*eksepsi\", # Start of legal reasoning\n",
        "            r\"menimbang,\\s*bahwa\\s*majelis\\s*hakim\\s*berpendapat\",\n",
        "            r\"menimbang,\\s*bahwa\\s*oleh\\s*karena\\s*itu\\s*dengan\\s*memperhatikan\"\n",
        "        ]\n",
        "        argumen_keywords_end = [ # Stop before the final verdict/amar\n",
        "            r\"memperhatikan pasal-pasal dari undang-undang\",\n",
        "            r\"mengadili,\",\n",
        "            r\"amar\\s*putusan\",\n",
        "            r\"mengadili\",\n",
        "            r\"memutuskan\",\n",
        "            r\"menetapkan\"\n",
        "        ]\n",
        "\n",
        "        # Regex for \"Pasal Digunakan\" (example, very basic, often complex)\n",
        "        # Looks for patterns like \"Pasal X ayat (Y) UU No. Z Tahun A\" or KUHP/KUHAP etc.\n",
        "        pasal_regex_patterns = [\n",
        "            r\"pasal\\s*\\d+\\s*(ayat\\s*\\(?\\s*\\d+\\s*\\)?\\s*)?(huruf\\s*[a-z]\\s*)?\\s*(uu|undang-undang)\\s*(nomor|no\\.)?\\s*\\d+\\s*tahun\\s*\\d+\",\n",
        "            r\"pasal\\s*\\d+\\s*(ayat\\s*\\(?\\s*\\d+\\s*\\)?\\s*)?\\s*kuhp(?:idana)?\",\n",
        "            r\"pasal\\s*\\d+\\s*(ayat\\s*\\(?\\s*\\d+\\s*\\)?\\s*)?\\s*kuhperdata\",\n",
        "            r\"peraturan pemerintah\\s*(nomor|no\\.)?\\s*\\d+\\s*tahun\\s*\\d+\",\n",
        "            r\"peraturan menteri keuangan\\s*(nomor|no\\.)?[\\s\\w./-]+\", # Mencakup format seperti 78/PMK.03/2010\n",
        "            r\"keputusan direktur jenderal pajak\\s*(nomor|no\\.)?[\\s\\w./-]+\", # Mencakup format seperti KEP-539/PJ./2001\n",
        "            r\"surat edaran\\s*(direktur jenderal pajak)?\\s*(nomor|no\\.)?[\\s\\w./-]+\" # Mencakup format seperti SE-90/PJ/2011\n",
        "        ]\n",
        "\n",
        "        # Function to extract ringkasan fakta with fallback mechanism\n",
        "        def extract_ringkasan_fakta_enhanced(full_text, raw_filename, case_id):\n",
        "            \"\"\"\n",
        "            Enhanced function to extract ringkasan fakta with multiple fallback levels:\n",
        "            1. Try to extract from full_text (main putusan)\n",
        "            2. If not found, try to extract from raw text file directly\n",
        "            3. If still not found, return \"TIDAK TERDETEKSI\"\n",
        "            \"\"\"\n",
        "            print(f\"  -> Extracting ringkasan fakta for case_id: {case_id}\")\n",
        "\n",
        "            # Level 1: Try extracting from main full_text\n",
        "            ringkasan_level1 = extract_section_heuristic(\n",
        "                full_text, fakta_keywords_start, fakta_keywords_end, limit_chars=4000\n",
        "            )\n",
        "\n",
        "            if ringkasan_level1 and ringkasan_level1.strip() and len(ringkasan_level1.strip()) > 50:\n",
        "                print(f\"  -> Ringkasan fakta found in main text (Level 1)\")\n",
        "                return ringkasan_level1\n",
        "\n",
        "            # Level 2: Try reading raw file directly and extract from there\n",
        "            print(f\"  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\")\n",
        "            try:\n",
        "                if pd.notna(raw_filename) and raw_filename.strip():\n",
        "                    raw_text_direct = read_raw_text_file(raw_filename, PATH_RAW_TEXT_INPUT)\n",
        "                    if raw_text_direct and raw_text_direct.strip():\n",
        "                        ringkasan_level2 = extract_section_heuristic(\n",
        "                            raw_text_direct, fakta_keywords_start, fakta_keywords_end, limit_chars=4000\n",
        "                        )\n",
        "\n",
        "                        if ringkasan_level2 and ringkasan_level2.strip() and len(ringkasan_level2.strip()) > 50:\n",
        "                            print(f\"  -> Ringkasan fakta found in raw file (Level 2)\")\n",
        "                            return ringkasan_level2\n",
        "                        else:\n",
        "                            print(f\"  -> Ringkasan fakta not found in raw file either\")\n",
        "                    else:\n",
        "                        print(f\"  -> Raw file is empty or could not be read\")\n",
        "                else:\n",
        "                    print(f\"  -> Raw filename is invalid\")\n",
        "            except Exception as e:\n",
        "                print(f\"  -> Error reading raw file: {str(e)}\")\n",
        "\n",
        "            # Level 3: Not found anywhere\n",
        "            print(f\"  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\")\n",
        "            return \"TIDAK TERDETEKSI\"\n",
        "\n",
        "        for index, row in df_initial.iterrows():\n",
        "            full_text = str(row['full_text_putusan'])\n",
        "            full_text_lower = full_text.lower() # Gunakan versi lowercase untuk pencarian\n",
        "            raw_filename = row.get('nama_file_raw_text', '')\n",
        "            case_id = row.get('case_id', f'Index-{index}')\n",
        "\n",
        "            print(f\"Processing case_id: {case_id}...\")\n",
        "\n",
        "            # Ekstraksi Pihak Terlibat (Lebih Akurat)\n",
        "            # Pola: PEMOHON... melawan: TERMOHON...\n",
        "            pihak_match = re.search(\n",
        "                r\"(pemohon peninjauan kembali.*?)(?:melawan:|lawan)(.*?)(?:mahkamah agung tersebut;)\",\n",
        "                full_text,\n",
        "                re.IGNORECASE | re.DOTALL\n",
        "            )\n",
        "            if pihak_match:\n",
        "                pemohon_text = re.sub(r'\\s+', ' ', pihak_match.group(1)).strip()\n",
        "                termohon_text = re.sub(r'\\s+', ' ', pihak_match.group(2)).strip()\n",
        "                df_initial.loc[index, 'pihak_terlibat_extracted'] = f\"Pemohon: {pemohon_text} vs Termohon: {termohon_text}\"\n",
        "            else:\n",
        "                # Fallback jika pola utama tidak ditemukan\n",
        "                df_initial.loc[index, 'pihak_terlibat_extracted'] = row.get('nama_pihak', 'N/A')\n",
        "\n",
        "            # Extract Ringkasan Fakta (menggunakan enhanced function dengan fallback)\n",
        "            df_initial.loc[index, 'ringkasan_fakta'] = extract_ringkasan_fakta_enhanced(\n",
        "                full_text, raw_filename, case_id\n",
        "            )\n",
        "\n",
        "            # Extract Argumen Hukum Utama (menggunakan keywords baru)\n",
        "            df_initial.loc[index, 'argumen_hukum_utama'] = extract_section_heuristic(\n",
        "                full_text, argumen_keywords_start, argumen_keywords_end, limit_chars=5000\n",
        "            ) or \"TIDAK TERDETEKSI\"\n",
        "\n",
        "            # Extract Pasal Digunakan (menggunakan regex baru)\n",
        "            found_pasal_list = []\n",
        "            # Cari di seluruh teks (versi lowercase)\n",
        "            for pattern in pasal_regex_patterns:\n",
        "                matches = re.findall(pattern, full_text_lower)\n",
        "                for match in matches:\n",
        "                    pasal_text = match if isinstance(match, str) else \" \".join(filter(None, match))\n",
        "                    normalized_pasal = ' '.join(pasal_text.split()).strip()\n",
        "                    if normalized_pasal and normalized_pasal not in found_pasal_list:\n",
        "                        found_pasal_list.append(normalized_pasal)\n",
        "\n",
        "            # Gabungkan hasil dan bersihkan dari duplikat\n",
        "            df_initial.loc[index, 'pasal_digunakan_extracted'] = \"; \".join(sorted(list(set(found_pasal_list)))) if found_pasal_list else row.get('pasal_digunakan', '')\n",
        "\n",
        "        # 3. Feature Engineering\n",
        "        print(f\"\\n[3. Performing Feature Engineering]\")\n",
        "\n",
        "        # Calculate length (jumlah kata) for key text fields\n",
        "        df_initial['jumlah_kata_full_text'] = df_initial['full_text_putusan'].apply(count_words)\n",
        "        df_initial['jumlah_kata_ringkasan_fakta'] = df_initial['ringkasan_fakta'].apply(count_words)\n",
        "        df_initial['jumlah_kata_argumen_hukum'] = df_initial['argumen_hukum_utama'].apply(count_words)\n",
        "        print(\"Word counts calculated.\")\n",
        "\n",
        "        # Bag-of-Words (BoW) - Will be implicitly handled by TF-IDF in Tahap 3.\n",
        "        # For this stage, we can note its conceptual presence or skip explicit generation\n",
        "        # to avoid large sparse matrices in this intermediate CSV.\n",
        "        # If needed, one could tokenize and store counts, but it's often not stored directly.\n",
        "        print(\"Conceptual Bag-of-Words representation will be handled in later stages (e.g., TF-IDF).\")\n",
        "\n",
        "        # QA-pairs sederhana - This is an advanced feature.\n",
        "        # For a \"sederhana\" system, this could be:\n",
        "        # - Placeholder: Indicating it's a potential future enhancement.\n",
        "        # - Heuristic: Extracting questions from \"Pertimbangan Hukum\" if any explicit questions are posed.\n",
        "        # For now, we'll add a placeholder column.\n",
        "        df_initial['qa_pairs_sederhana'] = \"NOT_IMPLEMENTED\" # Placeholder\n",
        "        print(\"QA-pairs (sederhana) marked as NOT_IMPLEMENTED (advanced feature).\")\n",
        "\n",
        "        # 4. Prepare Final DataFrame and Save\n",
        "        print(f\"\\n[4. Preparing and Saving Processed Data]\")\n",
        "\n",
        "        # Select and rename columns to match PDF example where possible\n",
        "        # \"case_id\", \"no_perkara\", \"tanggal\", \"ringkasan_fakta\", \"pasal\", \"pihak\", \"text_full\"\n",
        "        df_processed = df_initial.rename(columns={\n",
        "            'nomor_perkara': 'no_perkara',\n",
        "            'tanggal_putusan': 'tanggal', # Assuming tanggal_putusan is the main date\n",
        "            'pasal_digunakan_extracted': 'pasal', # Using the extracted/refined one\n",
        "            'pihak_terlibat_extracted': 'pihak',   # Using the extracted/refined one\n",
        "            'full_text_putusan': 'text_full' # Full text is important\n",
        "        })\n",
        "\n",
        "        # Ensure all required columns from PDF example are present, add if missing\n",
        "        required_cols = [\"case_id\", \"no_perkara\", \"tanggal\", \"ringkasan_fakta\", \"pasal\", \"pihak\", \"text_full\"]\n",
        "        for col in required_cols:\n",
        "            if col not in df_processed.columns:\n",
        "                df_processed[col] = df_initial.get(col, pd.NA) # Get from original if renamed, else NA\n",
        "\n",
        "        # Add other valuable columns (metadata from scraper, engineered features)\n",
        "        # Keep original 'jenis_perkara', 'amar_putusan', etc.\n",
        "        # Keep word counts\n",
        "        additional_cols_to_keep = [\n",
        "            'judul_putusan', 'jenis_perkara', 'tingkat_proses', 'kata_kunci',\n",
        "            'tahun_dokumen', 'tanggal_register', 'lembaga_peradilan', 'amar_putusan',\n",
        "            'link_sumber', 'link_pdf', 'nama_file_pdf', 'nama_file_raw_text',\n",
        "            'jumlah_kata_full_text', 'jumlah_kata_ringkasan_fakta', 'jumlah_kata_argumen_hukum',\n",
        "            'argumen_hukum_utama', # Retain this important feature\n",
        "            'qa_pairs_sederhana'\n",
        "        ]\n",
        "\n",
        "        final_columns_ordered = required_cols + [col for col in additional_cols_to_keep if col in df_processed.columns and col not in required_cols]\n",
        "        # Ensure no duplicate columns and all are present\n",
        "        final_columns_ordered = sorted(list(set(final_columns_ordered)), key=final_columns_ordered.index)\n",
        "        df_processed = df_processed[final_columns_ordered]\n",
        "\n",
        "        # Save to CSV\n",
        "        processed_csv_filename = \"cases_processed.csv\"\n",
        "        processed_csv_filepath = os.path.join(PATH_PROCESSED_OUTPUT, processed_csv_filename)\n",
        "        df_processed.to_csv(processed_csv_filepath, index=False, encoding='utf-8')\n",
        "        print(f\"Processed data saved to: {processed_csv_filepath}\")\n",
        "\n",
        "        # Save to JSON (optional, as per PDF )\n",
        "        processed_json_filename = \"cases_processed.json\"\n",
        "        processed_json_filepath = os.path.join(PATH_PROCESSED_OUTPUT, processed_json_filename)\n",
        "        df_processed.to_json(processed_json_filepath, orient='records', indent=4, force_ascii=False)\n",
        "        print(f\"Processed data also saved to: {processed_json_filepath}\")\n",
        "\n",
        "        print(\"\\n--- Sample of Processed Data ---\")\n",
        "        display(df_processed.head())\n",
        "        print(f\"\\nColumns in processed DataFrame: {df_processed.columns.tolist()}\")\n",
        "        print(f\"Shape of processed DataFrame: {df_processed.shape}\")\n",
        "\n",
        "        # Summary statistics untuk ringkasan fakta\n",
        "        print(\"\\n--- Ringkasan Fakta Extraction Summary ---\")\n",
        "        ringkasan_status = df_processed['ringkasan_fakta'].apply(\n",
        "            lambda x: 'TERDETEKSI' if x != 'TIDAK TERDETEKSI' else 'TIDAK TERDETEKSI'\n",
        "        ).value_counts()\n",
        "        print(f\"Ringkasan Fakta Status:\\n{ringkasan_status}\")\n",
        "\n",
        "        # Show average length of detected ringkasan fakta\n",
        "        detected_ringkasan = df_processed[df_processed['ringkasan_fakta'] != 'TIDAK TERDETEKSI']['ringkasan_fakta']\n",
        "        if not detected_ringkasan.empty:\n",
        "            avg_length = detected_ringkasan.apply(len).mean()\n",
        "            print(f\"Average length of detected ringkasan fakta: {avg_length:.0f} characters\")\n",
        "\n",
        "print(\"\\nTahap 2: Case Representation - Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5aobjKtSUgJ6",
        "outputId": "9c2e0f24-263e-495a-bb9e-3e6a41470039"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Tahap 2: Case Representation\n",
            "\n",
            "[1. Loading Data]\n",
            "Loading latest scraper CSV: putusan_ma_Perdagangan_Orang_2025-06-25.csv\n",
            "Filtered data, remaining rows after removing invalid 'nama_file_raw_text': 42\n",
            "Loaded initial data with 42 records.\n",
            "Full text loaded into DataFrame.\n",
            "\n",
            "[2. Extracting/Refining Metadata & Text Features]\n",
            "Processing case_id: case_004...\n",
            "  -> Extracting ringkasan fakta for case_id: case_004\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_006...\n",
            "  -> Extracting ringkasan fakta for case_id: case_006\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_007...\n",
            "  -> Extracting ringkasan fakta for case_id: case_007\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_009...\n",
            "  -> Extracting ringkasan fakta for case_id: case_009\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_012...\n",
            "  -> Extracting ringkasan fakta for case_id: case_012\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_013...\n",
            "  -> Extracting ringkasan fakta for case_id: case_013\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_014...\n",
            "  -> Extracting ringkasan fakta for case_id: case_014\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_018...\n",
            "  -> Extracting ringkasan fakta for case_id: case_018\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_023...\n",
            "  -> Extracting ringkasan fakta for case_id: case_023\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_024...\n",
            "  -> Extracting ringkasan fakta for case_id: case_024\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_026...\n",
            "  -> Extracting ringkasan fakta for case_id: case_026\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_033...\n",
            "  -> Extracting ringkasan fakta for case_id: case_033\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_035...\n",
            "  -> Extracting ringkasan fakta for case_id: case_035\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_036...\n",
            "  -> Extracting ringkasan fakta for case_id: case_036\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_043...\n",
            "  -> Extracting ringkasan fakta for case_id: case_043\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_045...\n",
            "  -> Extracting ringkasan fakta for case_id: case_045\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_046...\n",
            "  -> Extracting ringkasan fakta for case_id: case_046\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_049...\n",
            "  -> Extracting ringkasan fakta for case_id: case_049\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_050...\n",
            "  -> Extracting ringkasan fakta for case_id: case_050\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_051...\n",
            "  -> Extracting ringkasan fakta for case_id: case_051\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_059...\n",
            "  -> Extracting ringkasan fakta for case_id: case_059\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_062...\n",
            "  -> Extracting ringkasan fakta for case_id: case_062\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_063...\n",
            "  -> Extracting ringkasan fakta for case_id: case_063\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_065...\n",
            "  -> Extracting ringkasan fakta for case_id: case_065\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_066...\n",
            "  -> Extracting ringkasan fakta for case_id: case_066\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_067...\n",
            "  -> Extracting ringkasan fakta for case_id: case_067\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_068...\n",
            "  -> Extracting ringkasan fakta for case_id: case_068\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_071...\n",
            "  -> Extracting ringkasan fakta for case_id: case_071\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_073...\n",
            "  -> Extracting ringkasan fakta for case_id: case_073\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_074...\n",
            "  -> Extracting ringkasan fakta for case_id: case_074\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_075...\n",
            "  -> Extracting ringkasan fakta for case_id: case_075\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_076...\n",
            "  -> Extracting ringkasan fakta for case_id: case_076\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_077...\n",
            "  -> Extracting ringkasan fakta for case_id: case_077\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_078...\n",
            "  -> Extracting ringkasan fakta for case_id: case_078\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_079...\n",
            "  -> Extracting ringkasan fakta for case_id: case_079\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_080...\n",
            "  -> Extracting ringkasan fakta for case_id: case_080\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_082...\n",
            "  -> Extracting ringkasan fakta for case_id: case_082\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_083...\n",
            "  -> Extracting ringkasan fakta for case_id: case_083\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_085...\n",
            "  -> Extracting ringkasan fakta for case_id: case_085\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_089...\n",
            "  -> Extracting ringkasan fakta for case_id: case_089\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "Processing case_id: case_095...\n",
            "  -> Extracting ringkasan fakta for case_id: case_095\n",
            "  -> Ringkasan fakta found in main text (Level 1)\n",
            "Processing case_id: case_096...\n",
            "  -> Extracting ringkasan fakta for case_id: case_096\n",
            "  -> Ringkasan fakta not found in main text, trying raw file (Level 2)...\n",
            "  -> Ringkasan fakta not found in raw file either\n",
            "  -> Ringkasan fakta TIDAK TERDETEKSI after all attempts\n",
            "\n",
            "[3. Performing Feature Engineering]\n",
            "Word counts calculated.\n",
            "Conceptual Bag-of-Words representation will be handled in later stages (e.g., TF-IDF).\n",
            "QA-pairs (sederhana) marked as NOT_IMPLEMENTED (advanced feature).\n",
            "\n",
            "[4. Preparing and Saving Processed Data]\n",
            "Processed data saved to: /content/drive/MyDrive/Penalaran Komputer UAS/data/processed/cases_processed.csv\n",
            "Processed data also saved to: /content/drive/MyDrive/Penalaran Komputer UAS/data/processed/cases_processed.json\n",
            "\n",
            "--- Sample of Processed Data ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    case_id                    no_perkara            tanggal  \\\n",
              "0  case_004             4/PID/2021/PT MND   10 Februari 2021   \n",
              "2  case_006       131/Pid.Sus/2018/PN Wkb    17 Januari 2019   \n",
              "3  case_007            421 K/PID.SUS/2011                  —   \n",
              "5  case_009       442/Pid.Sus/2020/PN Cbi  21 September 2020   \n",
              "7  case_012  1163/Pid.Sus/2020/PN Jkt.Utr    1 Desember 2020   \n",
              "\n",
              "                                     ringkasan_fakta  \\\n",
              "0  oleh PenuntutUmum didakwa berdasarkan surat da...   \n",
              "2  oleh PenuntutUmum didakwa berdasarkan surat da...   \n",
              "3                                   TIDAK TERDETEKSI   \n",
              "5  oleh PenuntutUmum didakwa berdasarkan Surat Da...   \n",
              "7                                   TIDAK TERDETEKSI   \n",
              "\n",
              "                                               pasal       pihak  \\\n",
              "0  ayat (1) undang-undang nomor; ayat (2) undang-...  N/A vs N/A   \n",
              "2  ayat (2) undang-undang nomor; undang-undang nomor  N/A vs N/A   \n",
              "3      ayat (1) undang-undang no.; ayat (1) uu nomor  N/A vs N/A   \n",
              "5                                                  —  N/A vs N/A   \n",
              "7                                                  —  N/A vs N/A   \n",
              "\n",
              "                                           text_full  \\\n",
              "0  Direktori Putusan Mahkamah Agung Republik Indo...   \n",
              "2  Direktori Putusan Mahkamah Agung Republik Indo...   \n",
              "3  Direktori Putusan Mahkamah Agung Republik Indo...   \n",
              "5  Direktori Putusan Mahkamah Agung Republik Indo...   \n",
              "7  Direktori Putusan Mahkamah Agung Republik Indo...   \n",
              "\n",
              "                                       judul_putusan  \\\n",
              "0  Putusan PT MANADO Nomor 4/PID/2021/PT MND Tang...   \n",
              "2  Putusan PN WAIKABUBAK Nomor 131/Pid.Sus/2018/P...   \n",
              "3  Putusan MAHKAMAH AGUNG Nomor 421 K/PID.SUS/201...   \n",
              "5  Putusan PN CIBINONG Nomor 442/Pid.Sus/2020/PN ...   \n",
              "7  Putusan PN JAKARTA UTARA Nomor 1163/Pid.Sus/20...   \n",
              "\n",
              "                                   jenis_perkara tingkat_proses  ...  \\\n",
              "0  Pidana Khusus Pidana Khusus Perdagangan Orang        Banding  ...   \n",
              "2  Pidana Khusus Pidana Khusus Perdagangan Orang        Pertama  ...   \n",
              "3                                  Pidana Khusus         Kasasi  ...   \n",
              "5  Pidana Khusus Pidana Khusus Perdagangan Orang        Pertama  ...   \n",
              "7  Pidana Khusus Pidana Khusus Perdagangan Orang        Pertama  ...   \n",
              "\n",
              "  amar_putusan                                        link_sumber  \\\n",
              "0    Lain-lain  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "2    Lain-lain  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "3        Kabul  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "5    Lain-lain  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "7    Lain-lain  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "\n",
              "                                            link_pdf  \\\n",
              "0  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "2  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "3  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "5  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "7  https://putusan3.mahkamahagung.go.id/direktori...   \n",
              "\n",
              "                                       nama_file_pdf  \\\n",
              "0       putusan_4_pid_2021_pt_mnd_20250625225632.pdf   \n",
              "2  putusan_131_pid.sus_2018_pn_wkb_20250625225651...   \n",
              "3      putusan_421_k_pid.sus_2011_20250625225702.pdf   \n",
              "5  putusan_442_pid.sus_2020_pn_cbi_20250625225725...   \n",
              "7  putusan_1163_pid.sus_2020_pn_jkt.utr_202506252...   \n",
              "\n",
              "                          nama_file_raw_text jumlah_kata_full_text  \\\n",
              "0             case_4_PID_2021_PT MND_004.txt                  5042   \n",
              "2       case_131_Pid.Sus_2018_PN Wkb_006.txt                 18813   \n",
              "3            case_421 K_PID.SUS_2011_007.txt                  2699   \n",
              "5       case_442_Pid.Sus_2020_PN Cbi_009.txt                 11701   \n",
              "7  case_1163_Pid.Sus_2020_PN Jkt.Utr_012.txt                 10053   \n",
              "\n",
              "  jumlah_kata_ringkasan_fakta jumlah_kata_argumen_hukum  \\\n",
              "0                          68                       107   \n",
              "2                          81                         2   \n",
              "3                           2                       303   \n",
              "5                          68                         2   \n",
              "7                           2                         2   \n",
              "\n",
              "                                 argumen_hukum_utama  qa_pairs_sederhana  \n",
              "0  danpendapat Majelis Hakim Pengadilan Tingkat P...     NOT_IMPLEMENTED  \n",
              "2                                   TIDAK TERDETEKSI     NOT_IMPLEMENTED  \n",
              "3  yang salah. Judex facti tidak cermat mempertim...     NOT_IMPLEMENTED  \n",
              "5                                   TIDAK TERDETEKSI     NOT_IMPLEMENTED  \n",
              "7                                   TIDAK TERDETEKSI     NOT_IMPLEMENTED  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af3b17ca-28ec-4af7-b2a1-00e0d83fdf05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case_id</th>\n",
              "      <th>no_perkara</th>\n",
              "      <th>tanggal</th>\n",
              "      <th>ringkasan_fakta</th>\n",
              "      <th>pasal</th>\n",
              "      <th>pihak</th>\n",
              "      <th>text_full</th>\n",
              "      <th>judul_putusan</th>\n",
              "      <th>jenis_perkara</th>\n",
              "      <th>tingkat_proses</th>\n",
              "      <th>...</th>\n",
              "      <th>amar_putusan</th>\n",
              "      <th>link_sumber</th>\n",
              "      <th>link_pdf</th>\n",
              "      <th>nama_file_pdf</th>\n",
              "      <th>nama_file_raw_text</th>\n",
              "      <th>jumlah_kata_full_text</th>\n",
              "      <th>jumlah_kata_ringkasan_fakta</th>\n",
              "      <th>jumlah_kata_argumen_hukum</th>\n",
              "      <th>argumen_hukum_utama</th>\n",
              "      <th>qa_pairs_sederhana</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>case_004</td>\n",
              "      <td>4/PID/2021/PT MND</td>\n",
              "      <td>10 Februari 2021</td>\n",
              "      <td>oleh PenuntutUmum didakwa berdasarkan surat da...</td>\n",
              "      <td>ayat (1) undang-undang nomor; ayat (2) undang-...</td>\n",
              "      <td>N/A vs N/A</td>\n",
              "      <td>Direktori Putusan Mahkamah Agung Republik Indo...</td>\n",
              "      <td>Putusan PT MANADO Nomor 4/PID/2021/PT MND Tang...</td>\n",
              "      <td>Pidana Khusus Pidana Khusus Perdagangan Orang</td>\n",
              "      <td>Banding</td>\n",
              "      <td>...</td>\n",
              "      <td>Lain-lain</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>putusan_4_pid_2021_pt_mnd_20250625225632.pdf</td>\n",
              "      <td>case_4_PID_2021_PT MND_004.txt</td>\n",
              "      <td>5042</td>\n",
              "      <td>68</td>\n",
              "      <td>107</td>\n",
              "      <td>danpendapat Majelis Hakim Pengadilan Tingkat P...</td>\n",
              "      <td>NOT_IMPLEMENTED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>case_006</td>\n",
              "      <td>131/Pid.Sus/2018/PN Wkb</td>\n",
              "      <td>17 Januari 2019</td>\n",
              "      <td>oleh PenuntutUmum didakwa berdasarkan surat da...</td>\n",
              "      <td>ayat (2) undang-undang nomor; undang-undang nomor</td>\n",
              "      <td>N/A vs N/A</td>\n",
              "      <td>Direktori Putusan Mahkamah Agung Republik Indo...</td>\n",
              "      <td>Putusan PN WAIKABUBAK Nomor 131/Pid.Sus/2018/P...</td>\n",
              "      <td>Pidana Khusus Pidana Khusus Perdagangan Orang</td>\n",
              "      <td>Pertama</td>\n",
              "      <td>...</td>\n",
              "      <td>Lain-lain</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>putusan_131_pid.sus_2018_pn_wkb_20250625225651...</td>\n",
              "      <td>case_131_Pid.Sus_2018_PN Wkb_006.txt</td>\n",
              "      <td>18813</td>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "      <td>TIDAK TERDETEKSI</td>\n",
              "      <td>NOT_IMPLEMENTED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>case_007</td>\n",
              "      <td>421 K/PID.SUS/2011</td>\n",
              "      <td>—</td>\n",
              "      <td>TIDAK TERDETEKSI</td>\n",
              "      <td>ayat (1) undang-undang no.; ayat (1) uu nomor</td>\n",
              "      <td>N/A vs N/A</td>\n",
              "      <td>Direktori Putusan Mahkamah Agung Republik Indo...</td>\n",
              "      <td>Putusan MAHKAMAH AGUNG Nomor 421 K/PID.SUS/201...</td>\n",
              "      <td>Pidana Khusus</td>\n",
              "      <td>Kasasi</td>\n",
              "      <td>...</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>putusan_421_k_pid.sus_2011_20250625225702.pdf</td>\n",
              "      <td>case_421 K_PID.SUS_2011_007.txt</td>\n",
              "      <td>2699</td>\n",
              "      <td>2</td>\n",
              "      <td>303</td>\n",
              "      <td>yang salah. Judex facti tidak cermat mempertim...</td>\n",
              "      <td>NOT_IMPLEMENTED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>case_009</td>\n",
              "      <td>442/Pid.Sus/2020/PN Cbi</td>\n",
              "      <td>21 September 2020</td>\n",
              "      <td>oleh PenuntutUmum didakwa berdasarkan Surat Da...</td>\n",
              "      <td>—</td>\n",
              "      <td>N/A vs N/A</td>\n",
              "      <td>Direktori Putusan Mahkamah Agung Republik Indo...</td>\n",
              "      <td>Putusan PN CIBINONG Nomor 442/Pid.Sus/2020/PN ...</td>\n",
              "      <td>Pidana Khusus Pidana Khusus Perdagangan Orang</td>\n",
              "      <td>Pertama</td>\n",
              "      <td>...</td>\n",
              "      <td>Lain-lain</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>putusan_442_pid.sus_2020_pn_cbi_20250625225725...</td>\n",
              "      <td>case_442_Pid.Sus_2020_PN Cbi_009.txt</td>\n",
              "      <td>11701</td>\n",
              "      <td>68</td>\n",
              "      <td>2</td>\n",
              "      <td>TIDAK TERDETEKSI</td>\n",
              "      <td>NOT_IMPLEMENTED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>case_012</td>\n",
              "      <td>1163/Pid.Sus/2020/PN Jkt.Utr</td>\n",
              "      <td>1 Desember 2020</td>\n",
              "      <td>TIDAK TERDETEKSI</td>\n",
              "      <td>—</td>\n",
              "      <td>N/A vs N/A</td>\n",
              "      <td>Direktori Putusan Mahkamah Agung Republik Indo...</td>\n",
              "      <td>Putusan PN JAKARTA UTARA Nomor 1163/Pid.Sus/20...</td>\n",
              "      <td>Pidana Khusus Pidana Khusus Perdagangan Orang</td>\n",
              "      <td>Pertama</td>\n",
              "      <td>...</td>\n",
              "      <td>Lain-lain</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>https://putusan3.mahkamahagung.go.id/direktori...</td>\n",
              "      <td>putusan_1163_pid.sus_2020_pn_jkt.utr_202506252...</td>\n",
              "      <td>case_1163_Pid.Sus_2020_PN Jkt.Utr_012.txt</td>\n",
              "      <td>10053</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>TIDAK TERDETEKSI</td>\n",
              "      <td>NOT_IMPLEMENTED</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af3b17ca-28ec-4af7-b2a1-00e0d83fdf05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af3b17ca-28ec-4af7-b2a1-00e0d83fdf05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af3b17ca-28ec-4af7-b2a1-00e0d83fdf05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ef1e6a63-77ec-4ab8-9cb7-a306502a2e32\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef1e6a63-77ec-4ab8-9cb7-a306502a2e32')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ef1e6a63-77ec-4ab8-9cb7-a306502a2e32 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns in processed DataFrame: ['case_id', 'no_perkara', 'tanggal', 'ringkasan_fakta', 'pasal', 'pihak', 'text_full', 'judul_putusan', 'jenis_perkara', 'tingkat_proses', 'kata_kunci', 'tahun_dokumen', 'tanggal_register', 'lembaga_peradilan', 'amar_putusan', 'link_sumber', 'link_pdf', 'nama_file_pdf', 'nama_file_raw_text', 'jumlah_kata_full_text', 'jumlah_kata_ringkasan_fakta', 'jumlah_kata_argumen_hukum', 'argumen_hukum_utama', 'qa_pairs_sederhana']\n",
            "Shape of processed DataFrame: (42, 24)\n",
            "\n",
            "--- Ringkasan Fakta Extraction Summary ---\n",
            "Ringkasan Fakta Status:\n",
            "ringkasan_fakta\n",
            "TIDAK TERDETEKSI    30\n",
            "TERDETEKSI          12\n",
            "Name: count, dtype: int64\n",
            "Average length of detected ringkasan fakta: 2547 characters\n",
            "\n",
            "Tahap 2: Case Representation - Complete.\n"
          ]
        }
      ]
    }
  ]
}